#!/usr/bin/env python3
"""
RUZANNA - –û—Å–Ω–æ–≤–Ω–æ–π –º–æ–¥—É–ª—å –æ–±—É—á–µ–Ω–∏—è –ø—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–≥–æ –ò–ò
–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–æ–Ω–Ω–æ–π —Å–∏—Å—Ç–µ–º–æ–π
"""

import os
import sys
import json
import time
import argparse
import warnings
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Optional, Tuple
from path_manager import PathManager

# ============================================================================
# –ù–ê–°–¢–†–û–ô–ö–ê –ü–£–¢–ï–ô –ò –ò–ú–ü–û–†–¢–û–í
# ============================================================================

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç–∏ –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞
current_dir = Path(__file__).parent
sys.path.insert(0, str(current_dir / "core"))
sys.path.insert(0, str(current_dir / "data"))

# –ü–æ–¥–∞–≤–ª–µ–Ω–∏–µ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–π
warnings.filterwarnings("ignore", category=FutureWarning)
warnings.filterwarnings("ignore", category=UserWarning)
warnings.filterwarnings("ignore", message="torch.utils.checkpoint")

# –ò–º–ø–æ—Ä—Ç –Ω–∞—à–∏—Ö –º–æ–¥—É–ª–µ–π
try:
    from config_loader import ConfigManager
except ImportError as e:
    print(f"‚ùå –û—à–∏–±–∫–∞ –∏–º–ø–æ—Ä—Ç–∞ config_loader: {e}")
    print("–£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Ñ–∞–π–ª core/config_loader.py —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")
    sys.exit(1)

# –ò–º–ø–æ—Ä—Ç –±–∏–±–ª–∏–æ—Ç–µ–∫ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
try:
    import torch
    import torch.nn as nn
    from torch.utils.data import Dataset, DataLoader
    import transformers
    from transformers import (
        AutoTokenizer,
        AutoModelForCausalLM,
        get_linear_schedule_with_warmup,
        Trainer,
        TrainingArguments,
        DataCollatorForLanguageModeling
    )
    import numpy as np
    import pandas as pd
    from tqdm.auto import tqdm
    import psutil
    import GPUtil
    from colorama import init, Fore, Back, Style
    init(autoreset=True)
except ImportError as e:
    print(f"‚ùå –û—à–∏–±–∫–∞ –∏–º–ø–æ—Ä—Ç–∞ –±–∏–±–ª–∏–æ—Ç–µ–∫: {e}")
    print("–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏:")
    print("pip install torch transformers numpy pandas tqdm psutil gputil colorama")
    sys.exit(1)

# ============================================================================
# –ö–õ–ê–°–° –î–ê–¢–ê–°–ï–¢–ê
# ============================================================================

class PsychDialogueDataset(Dataset):
    """–î–∞—Ç–∞—Å–µ—Ç –ø—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫–∏—Ö –¥–∏–∞–ª–æ–≥–æ–≤"""
    
    def __init__(self, dialogues: List, tokenizer, max_length: int = 512):
        self.dialogues = dialogues
        self.tokenizer = tokenizer
        self.max_length = max_length
        
    def __len__(self) -> int:
        return len(self.dialogues)
    
    def __getitem__(self, idx: int) -> Dict:
        dialogue = self.dialogues[idx]
        
        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –¥–∏–∞–ª–æ–≥
        formatted = self.format_dialogue(dialogue)
        
        # –¢–æ–∫–µ–Ω–∏–∑–∏—Ä—É–µ–º
        encoding = self.tokenizer(
            formatted,
            max_length=self.max_length,
            padding="max_length",
            truncation=True,
            return_tensors="pt"
        )
        
        # –î–ª—è language modeling –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–µ –∂–µ —Ç–æ–∫–µ–Ω—ã –∫–∞–∫ labels
        return {
            'input_ids': encoding['input_ids'].squeeze(),
            'attention_mask': encoding['attention_mask'].squeeze(),
            'labels': encoding['input_ids'].squeeze().clone()  # –î–ª—è language modeling
        }
    
    def format_dialogue(self, dialogue) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –¥–∏–∞–ª–æ–≥ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è"""
        if isinstance(dialogue, dict):
            if 'text' in dialogue:
                text = dialogue['text']
            elif 'dialogue' in dialogue:
                text = dialogue['dialogue']
            else:
                # –ü—Ä–æ–±—É–µ–º –ø–æ–ª—É—á–∏—Ç—å –ø–µ—Ä–≤—ã–π —Å—Ç—Ä–æ–∫–æ–≤—ã–π –∫–ª—é—á
                for key, value in dialogue.items():
                    if isinstance(value, str) and len(value) > 10:
                        text = value
                        break
                else:
                    text = str(dialogue)
        elif isinstance(dialogue, str):
            text = dialogue
        else:
            text = str(dialogue)
        
        # –û—á–∏—â–∞–µ–º –∏ –¥–æ–±–∞–≤–ª—è–µ–º —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã
        text = text.strip()
        return f"[DIALOGUE_START]\n{text}\n[DIALOGUE_END]"

# ============================================================================
# –£–¢–ò–õ–ò–¢–´ –î–õ–Ø –ú–û–ù–ò–¢–û–†–ò–ù–ì–ê
# ============================================================================

class TrainingMonitor:
    """–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –ø—Ä–æ—Ü–µ—Å—Å–∞ –æ–±—É—á–µ–Ω–∏—è"""
    
    def __init__(self, log_dir: str = "./logs"):
        self.log_dir = Path(log_dir)
        self.log_dir.mkdir(exist_ok=True, parents=True)
        
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        self.log_file = self.log_dir / f"training_{timestamp}.log"
        self.csv_file = self.log_dir / f"metrics_{timestamp}.csv"
        
        self.metrics = []
        self.start_time = time.time()
        
    def log_step(self, step: int, loss: float, lr: float, phase: str = "train", **kwargs) -> Dict:
        """–õ–æ–≥–∏—Ä—É–µ—Ç —à–∞–≥ –æ–±—É—á–µ–Ω–∏—è"""
        timestamp = datetime.now().isoformat()
        elapsed = time.time() - self.start_time
        
        # –°–æ–±–∏—Ä–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏
        metric = {
            'timestamp': timestamp,
            'step': step,
            'loss': float(loss),
            'lr': float(lr),
            'phase': phase,
            'elapsed_seconds': elapsed,
            **kwargs
        }
        
        # –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ —Ä–µ—Å—É—Ä—Å–æ–≤
        try:
            metric['cpu_percent'] = psutil.cpu_percent()
            metric['ram_gb'] = psutil.virtual_memory().used / (1024**3)
            
            gpus = GPUtil.getGPUs()
            if gpus:
                gpu = gpus[0]
                metric['gpu_memory_gb'] = gpu.memoryUsed
                metric['gpu_load'] = gpu.load * 100
                metric['gpu_temp'] = gpu.temperature
        except Exception as e:
            print(f"{Fore.YELLOW}‚ö†Ô∏è  –û—à–∏–±–∫–∞ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ —Ä–µ—Å—É—Ä—Å–æ–≤: {e}{Style.RESET_ALL}")
        
        self.metrics.append(metric)
        
        # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –≤ –ª–æ–≥
        with open(self.log_file, 'a', encoding='utf-8') as f:
            log_line = f"{timestamp} | Step {step:5d} | Loss: {loss:.6f} | LR: {lr:.2e} | Phase: {phase}"
            if 'speed' in kwargs:
                log_line += f" | Speed: {kwargs['speed']:.1f} samples/s"
            f.write(log_line + "\n")
        
        # –ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤ CSV
        if step % 10 == 0:
            self.save_metrics()
        
        return metric
    
    def save_metrics(self):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –º–µ—Ç—Ä–∏–∫–∏ –≤ CSV"""
        if self.metrics:
            df = pd.DataFrame(self.metrics)
            df.to_csv(self.csv_file, index=False, encoding='utf-8')
    
    def print_status(self, step: int, total_steps: int, loss: float, lr: float, speed: float = None):
        """–ü–µ—á–∞—Ç–∞–µ—Ç —Å—Ç–∞—Ç—É—Å –æ–±—É—á–µ–Ω–∏—è"""
        percent = (step / total_steps) * 100 if total_steps > 0 else 0
        
        # –ü—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä
        bar_length = 30
        filled = int(bar_length * step // total_steps) if total_steps > 0 else 0
        bar = '‚ñà' * filled + '‚ñë' * (bar_length - filled)
        
        # –¶–≤–µ—Ç –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
        if percent < 33:
            color = Fore.RED
        elif percent < 66:
            color = Fore.YELLOW
        else:
            color = Fore.GREEN
        
        # –í—Ä–µ–º—è
        elapsed = time.time() - self.start_time
        if step > 0 and speed:
            remaining = (total_steps - step) / speed if speed > 0 else 0
            time_str = f"{int(elapsed//60):02d}:{int(elapsed%60):02d} | ETA: {int(remaining//60):02d}:{int(remaining%60):02d}"
        else:
            time_str = f"{int(elapsed//60):02d}:{int(elapsed%60):02d}"
        
        # –°—Ç–∞—Ç—É—Å
        status = f"\r{color}{bar}{Style.RESET_ALL} {percent:5.1f}% | "
        status += f"Step {step:4d}/{total_steps} | "
        status += f"Loss: {loss:.4f} | "
        status += f"LR: {lr:.2e} | "
        status += f"Time: {time_str}"
        
        if speed:
            status += f" | Speed: {speed:.1f} samp/s"
        
        print(status, end='', flush=True)
    
    def final_report(self):
        """–§–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç"""
        total_time = time.time() - self.start_time
        hours = int(total_time // 3600)
        minutes = int((total_time % 3600) // 60)
        seconds = int(total_time % 60)
        
        print(f"\n{Fore.CYAN}{'='*70}{Style.RESET_ALL}")
        print(f"{Fore.GREEN}üèÅ –û–ë–£–ß–ï–ù–ò–ï –ó–ê–í–ï–†–®–ï–ù–û{Style.RESET_ALL}")
        print(f"{Fore.CYAN}{'='*70}{Style.RESET_ALL}")
        print(f"–û–±—â–µ–µ –≤—Ä–µ–º—è: {hours:02d}:{minutes:02d}:{seconds:02d}")
        print(f"–õ–æ–≥–∏: {self.log_file}")
        print(f"–ú–µ—Ç—Ä–∏–∫–∏: {self.csv_file}")
        print(f"{Fore.CYAN}{'='*70}{Style.RESET_ALL}")

# ============================================================================
# –û–°–ù–û–í–ù–û–ô –ö–õ–ê–°–° –¢–†–ï–ù–ï–†–ê
# ============================================================================

class PsychAITrainer:
    """–¢—Ä–µ–Ω–µ—Ä –ø—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–≥–æ –ò–ò"""
    
    def __init__(self, config: Dict):
        self.config = config

         # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –º–µ–Ω–µ–¥–∂–µ—Ä –ø—É—Ç–µ–π
        self.path_manager = PathManager()
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –±–∞–∑–æ–≤—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é
        if output_base_dir:
            self.base_dir = Path(output_base_dir)
        else:
            # –ë–µ—Ä–µ–º –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞ –∏–ª–∏ —Å–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é
            base_from_config = config.get('paths', {}).get('base')
            if base_from_config:
                self.base_dir = Path(base_from_config)
            else:
                # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —Å–æ–∑–¥–∞–Ω–∏–µ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞
                exp_name = f"psych_train_{datetime.now().strftime('%Y%m%d_%H%M')}"
                self.base_dir = self.path_manager.create_experiment_dir(
                    base_path="./experiments",
                    experiment_name=exp_name
                )
        
        # –°–æ–∑–¥–∞–µ–º —Å–µ—Å—Å–∏—é
        self.session_dir = self.path_manager.create_session_dir(self.base_dir)
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –∫–æ–Ω—Ñ–∏–≥ —Å –ø—É—Ç—è–º–∏ —ç—Ç–æ–π —Å–µ—Å—Å–∏–∏
        self._update_config_paths()
        
        # –¢–µ–ø–µ—Ä—å –Ω–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ
        self.device = self._setup_device()
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥
        log_dir = self.session_dir / 'logs'
        self.monitor = TrainingMonitor(str(log_dir))
        
        # –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
        self.tokenizer = None
        self.model = None
        self.optimizer = None
        self.scheduler = None
        self.train_dataset = None
        self.val_dataset = None
        self.train_loader = None
        self.val_loader = None
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        self.stats = {
            'best_loss': float('inf'),
            'current_epoch': 0,
            'total_steps': 0,
            'checkpoint_paths': []
        }
        
        print(f"{Fore.CYAN}{'='*70}{Style.RESET_ALL}")
        print(f"{Fore.MAGENTA}üß† –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø –¢–†–ï–ù–ï–†–ê PSYCH AI{Style.RESET_ALL}")
        print(f"{Fore.CYAN}{'='*70}{Style.RESET_ALL}")
    
    def _update_config_paths(self):
        """–û–±–Ω–æ–≤–ª—è–µ—Ç –ø—É—Ç–∏ –≤ –∫–æ–Ω—Ñ–∏–≥–µ –Ω–∞ –∞–∫—Ç—É–∞–ª—å–Ω—ã–µ"""
        paths = self.path_manager.get_all_paths(self.session_dir)
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –∫–æ–Ω—Ñ–∏–≥
        if 'paths' not in self.config:
            self.config['paths'] = {}
        
        for key, path in paths.items():
            self.config['paths'][key] = str(path)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–æ–Ω—Ñ–∏–≥ —ç—Ç–æ–π —Å–µ—Å—Å–∏–∏
        config_path = self.session_dir / 'configs' / 'training_config.json'
        with open(config_path, 'w', encoding='utf-8') as f:
            json.dump(self.config, f, indent=2, ensure_ascii=False)

    def _setup_device(self) -> torch.device:
        """–ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è"""
        device_config = self.config.get('system', {}).get('device', 'cuda')
        
        if device_config == 'cuda' and torch.cuda.is_available():
            device = torch.device('cuda')
            gpu_name = torch.cuda.get_device_name(0)
            gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9
            print(f"{Fore.GREEN}‚úÖ –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è GPU: {gpu_name}{Style.RESET_ALL}")
            print(f"   –ü–∞–º—è—Ç—å: {gpu_memory:.1f} GB")
            print(f"   CUDA –≤–µ—Ä—Å–∏—è: {torch.version.cuda}")
        else:
            device = torch.device('cpu')
            print(f"{Fore.YELLOW}‚ö†Ô∏è  –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è CPU (CUDA –Ω–µ –¥–æ—Å—Ç—É–ø–Ω–∞){Style.RESET_ALL}")
        
        return device
    
    def load_data(self) -> List:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è"""
        print(f"\n{Fore.CYAN}üì• –ó–ê–ì–†–£–ó–ö–ê –î–ê–ù–ù–´–•{Style.RESET_ALL}")
        print(f"{Fore.CYAN}{'-'*40}{Style.RESET_ALL}")
        
        data_config = self.config.get('data', {})
        data_path = data_config.get('path', '')
        
        if not data_path:
            raise ValueError("–ü—É—Ç—å –∫ –¥–∞–Ω–Ω—ã–º –Ω–µ —É–∫–∞–∑–∞–Ω –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏")
        
        data_path = Path(data_path)
        if not data_path.exists():
            raise FileNotFoundError(f"–§–∞–π–ª –¥–∞–Ω–Ω—ã—Ö –Ω–µ –Ω–∞–π–¥–µ–Ω: {data_path}")
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        try:
            with open(data_path, 'r', encoding='utf-8') as f:
                dialogues = json.load(f)
            
            if not isinstance(dialogues, list):
                raise ValueError("–î–∞–Ω–Ω—ã–µ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å —Å–ø–∏—Å–∫–æ–º –¥–∏–∞–ª–æ–≥–æ–≤")
            
            # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
            max_dialogues = data_config.get('max_dialogues')
            if max_dialogues and len(dialogues) > max_dialogues:
                dialogues = dialogues[:max_dialogues]
                print(f"{Fore.YELLOW}‚ö†Ô∏è  –û–≥—Ä–∞–Ω–∏—á–µ–Ω–æ –¥–æ {max_dialogues} –¥–∏–∞–ª–æ–≥–æ–≤{Style.RESET_ALL}")
            
            print(f"{Fore.GREEN}‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(dialogues)} –¥–∏–∞–ª–æ–≥–æ–≤{Style.RESET_ALL}")
            print(f"   –ü—É—Ç—å: {data_path}")
            print(f"   –†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞: {data_path.stat().st_size / 1024 / 1024:.1f} MB")
            
            # –ü—Ä–∏–º–µ—Ä –¥–∏–∞–ª–æ–≥–∞
            if dialogues:
                sample = dialogues[0]
                if isinstance(sample, dict) and 'text' in sample:
                    preview = sample['text'][:100] + "..." if len(sample['text']) > 100 else sample['text']
                else:
                    preview = str(sample)[:100] + "..."
                print(f"   –ü—Ä–∏–º–µ—Ä: {preview}")
            
            return dialogues
            
        except json.JSONDecodeError as e:
            raise ValueError(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON: {e}")
        except Exception as e:
            raise Exception(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö: {e}")
    
    def prepare_tokenizer(self):
        """–ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä"""
        print(f"\n{Fore.CYAN}üî§ –ü–û–î–ì–û–¢–û–í–ö–ê –¢–û–ö–ï–ù–ò–ó–ê–¢–û–†–ê{Style.RESET_ALL}")
        print(f"{Fore.CYAN}{'-'*40}{Style.RESET_ALL}")
        
        model_config = self.config.get('model', {})
        model_name = model_config.get('name', 'EleutherAI/gpt-neo-2.7B')
        
        try:
            print(f"–ó–∞–≥—Ä—É–∑–∫–∞ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞: {model_name}...")
            self.tokenizer = AutoTokenizer.from_pretrained(model_name)
            
            # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã
            if not self.tokenizer.pad_token:
                self.tokenizer.pad_token = self.tokenizer.eos_token
                print(f"{Fore.YELLOW}‚ö†Ô∏è  –£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω pad_token = eos_token{Style.RESET_ALL}")
            
            # –î–æ–±–∞–≤–ª—è–µ–º –Ω–∞—à–∏ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã
            special_tokens = {
                'additional_special_tokens': ['[DIALOGUE_START]', '[DIALOGUE_END]']
            }
            self.tokenizer.add_special_tokens(special_tokens)
            
            print(f"{Fore.GREEN}‚úÖ –¢–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä –∑–∞–≥—Ä—É–∂–µ–Ω{Style.RESET_ALL}")
            print(f"   –ú–æ–¥–µ–ª—å: {model_name}")
            print(f"   –†–∞–∑–º–µ—Ä —Å–ª–æ–≤–∞—Ä—è: {len(self.tokenizer):,} —Ç–æ–∫–µ–Ω–æ–≤")
            print(f"   –ú–∞–∫—Å. –¥–ª–∏–Ω–∞: {self.tokenizer.model_max_length}")
            
            return self.tokenizer
            
        except Exception as e:
            raise Exception(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞: {e}")
    
    def prepare_model(self):
        """–ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç –º–æ–¥–µ–ª—å"""
        print(f"\n{Fore.CYAN}ü§ñ –ü–û–î–ì–û–¢–û–í–ö–ê –ú–û–î–ï–õ–ò{Style.RESET_ALL}")
        print(f"{Fore.CYAN}{'-'*40}{Style.RESET_ALL}")
        
        model_config = self.config.get('model', {})
        model_name = model_config.get('name', 'EleutherAI/gpt-neo-2.7B')
        
        try:
            print(f"–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏: {model_name}...")
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –¥–∞–Ω–Ω—ã—Ö
            precision = self.config.get('system', {}).get('precision', 'fp32')
            if precision == 'fp16' and self.device.type == 'cuda':
                torch_dtype = torch.float16
                print(f"   –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø–æ–ª–æ–≤–∏–Ω–Ω–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å (fp16)")
            else:
                torch_dtype = torch.float32
                print(f"   –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø–æ–ª–Ω–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å (fp32)")
            
            # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∑–∞–≥—Ä—É–∑–∫–∏
            load_kwargs = {
                'torch_dtype': torch_dtype,
                'device_map': 'auto' if self.device.type == 'cuda' else None,
            }
            
            # –û—Ç–∫–ª—é—á–∞–µ–º –∫—ç—à –µ—Å–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º gradient checkpointing
            if model_config.get('gradient_checkpointing', True):
                load_kwargs['use_cache'] = False
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
            self.model = AutoModelForCausalLM.from_pretrained(
                model_name,
                **load_kwargs
            )
            
            # –ü–µ—Ä–µ–Ω–æ—Å–∏–º –Ω–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –µ—Å–ª–∏ –Ω–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª–∏ device_map
            if 'device_map' not in load_kwargs or not load_kwargs['device_map']:
                self.model.to(self.device)
            
            # –í–∫–ª—é—á–∞–µ–º gradient checkpointing –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
            if model_config.get('gradient_checkpointing', True):
                self.model.gradient_checkpointing_enable()
                print(f"   Gradient checkpointing: {Fore.GREEN}–í–∫–ª—é—á–µ–Ω{Style.RESET_ALL}")
            
            # –ò–∑–º–µ–Ω—è–µ–º —Ä–∞–∑–º–µ—Ä —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –¥–ª—è –Ω–æ–≤—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤
            if self.tokenizer and len(self.tokenizer) != self.model.config.vocab_size:
                old_size = self.model.config.vocab_size
                self.model.resize_token_embeddings(len(self.tokenizer))
                print(f"   –†–∞–∑–º–µ—Ä —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –∏–∑–º–µ–Ω—ë–Ω: {old_size:,} ‚Üí {len(self.tokenizer):,}")
            
            # –°—á–∏—Ç–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
            total_params = sum(p.numel() for p in self.model.parameters())
            trainable_params = sum(p.numel() for p in self.model.parameters() if p.requires_grad)
            
            print(f"{Fore.GREEN}‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞{Style.RESET_ALL}")
            print(f"   –ü–∞—Ä–∞–º–µ—Ç—Ä—ã: {total_params:,} (–æ–±—É—á–∞–µ–º—ã—Ö: {trainable_params:,})")
            print(f"   –°–ª–æ–∏: {len(list(self.model.parameters()))}")
            
            return self.model
            
        except Exception as e:
            raise Exception(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}")
    
    def create_datasets(self, dialogues: List):
        """–°–æ–∑–¥–∞–µ—Ç —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã–π –∏ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç—ã"""
        print(f"\n{Fore.CYAN}üìä –°–û–ó–î–ê–ù–ò–ï –î–ê–¢–ê–°–ï–¢–û–í{Style.RESET_ALL}")
        print(f"{Fore.CYAN}{'-'*40}{Style.RESET_ALL}")
        
        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã
        data_config = self.config.get('data', {})
        tokenization_config = self.config.get('tokenization', {})
        
        train_split = data_config.get('train_split', 0.85)
        val_split = data_config.get('val_split', 0.15)
        max_length = tokenization_config.get('max_length', 512)
        
        # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
        n_total = len(dialogues)
        n_train = int(n_total * train_split)
        n_val = int(n_total * val_split)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º split
        if n_train + n_val > n_total:
            n_val = n_total - n_train
        
        train_dialogues = dialogues[:n_train]
        val_dialogues = dialogues[n_train:n_train + n_val]
        
        print(f"–í—Å–µ–≥–æ –¥–∏–∞–ª–æ–≥–æ–≤: {n_total:,}")
        print(f"–¢—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã—Ö: {n_train:,} ({train_split*100:.0f}%)")
        print(f"–í–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã—Ö: {n_val:,} ({val_split*100:.0f}%)")
        
        # –°–æ–∑–¥–∞–µ–º –¥–∞—Ç–∞—Å–µ—Ç—ã
        self.train_dataset = PsychDialogueDataset(
            train_dialogues, self.tokenizer, max_length
        )
        
        self.val_dataset = PsychDialogueDataset(
            val_dialogues, self.tokenizer, max_length
        )
        
        print(f"{Fore.GREEN}‚úÖ –î–∞—Ç–∞—Å–µ—Ç—ã —Å–æ–∑–¥–∞–Ω—ã{Style.RESET_ALL}")
        print(f"   –ú–∞–∫—Å. –¥–ª–∏–Ω–∞ —Ç–æ–∫–µ–Ω–æ–≤: {max_length}")
        
        return self.train_dataset, self.val_dataset
    
    def create_dataloaders(self):
        """–°–æ–∑–¥–∞–µ—Ç DataLoader'—ã"""
        print(f"\n{Fore.CYAN}üîÑ –°–û–ó–î–ê–ù–ò–ï DATALOADERS{Style.RESET_ALL}")
        print(f"{Fore.CYAN}{'-'*40}{Style.RESET_ALL}")
        
        training_config = self.config.get('training', {})
        batch_size = training_config.get('batch_size', 3)
        grad_accumulation = training_config.get('gradient_accumulation', 1)
        
        # –°–æ–∑–¥–∞–µ–º DataLoader –¥–ª—è —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∏
        self.train_loader = DataLoader(
            self.train_dataset,
            batch_size=batch_size,
            shuffle=True,
            num_workers=0,  # 0 –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è –ø—Ä–æ–±–ª–µ–º —Å Windows
            pin_memory=self.device.type == 'cuda'
        )
        
        # –°–æ–∑–¥–∞–µ–º DataLoader –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏
        self.val_loader = DataLoader(
            self.val_dataset,
            batch_size=max(1, batch_size // 2),  # –ú–µ–Ω—å—à–∏–π batch –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏
            shuffle=False,
            num_workers=0,
            pin_memory=self.device.type == 'cuda'
        )
        
        # –°—á–∏—Ç–∞–µ–º –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —à–∞–≥–æ–≤
        epochs = training_config.get('epochs', 3)
        steps_per_epoch = len(self.train_loader) // grad_accumulation
        if len(self.train_loader) % grad_accumulation != 0:
            steps_per_epoch += 1
        
        total_steps = steps_per_epoch * epochs
        self.stats['total_steps'] = total_steps
        
        print(f"{Fore.GREEN}‚úÖ DataLoader'—ã —Å–æ–∑–¥–∞–Ω—ã{Style.RESET_ALL}")
        print(f"   Batch size: {batch_size}")
        print(f"   Gradient accumulation: {grad_accumulation}")
        print(f"   –®–∞–≥–æ–≤ –Ω–∞ —ç–ø–æ—Ö—É: {steps_per_epoch:,}")
        print(f"   –í—Å–µ–≥–æ —à–∞–≥–æ–≤: {total_steps:,}")
        print(f"   Batches: train={len(self.train_loader)}, val={len(self.val_loader)}")
        
        return self.train_loader, self.val_loader
    
    def prepare_optimizer(self):
        """–ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä –∏ —à–µ–¥—É–ª–µ—Ä"""
        print(f"\n{Fore.CYAN}‚ö° –ü–û–î–ì–û–¢–û–í–ö–ê –û–ü–¢–ò–ú–ò–ó–ê–¢–û–†–ê{Style.RESET_ALL}")
        print(f"{Fore.CYAN}{'-'*40}{Style.RESET_ALL}")
        
        training_config = self.config.get('training', {})
        
        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–∞
        lr = training_config.get('learning_rate', 2e-4)
        weight_decay = training_config.get('weight_decay', 0.01)
        
        # –û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä
        self.optimizer = torch.optim.AdamW(
            self.model.parameters(),
            lr=lr,
            weight_decay=weight_decay,
            betas=(0.9, 0.999),
            eps=1e-8
        )
        
        # –®–µ–¥—É–ª–µ—Ä
        warmup_ratio = training_config.get('warmup_ratio', 0.9)
        warmup_steps = int(self.stats['total_steps'] * warmup_ratio)
        
        self.scheduler = get_linear_schedule_with_warmup(
            self.optimizer,
            num_warmup_steps=warmup_steps,
            num_training_steps=self.stats['total_steps']
        )
        
        print(f"{Fore.GREEN}‚úÖ –û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä –Ω–∞—Å—Ç—Ä–æ–µ–Ω{Style.RESET_ALL}")
        print(f"   –ê–ª–≥–æ—Ä–∏—Ç–º: AdamW")
        print(f"   Learning rate: {lr:.2e}")
        print(f"   Weight decay: {weight_decay}")
        print(f"   Warmup steps: {warmup_steps:,} ({warmup_ratio*100:.0f}%)")
        
        return self.optimizer, self.scheduler
    
    def save_checkpoint(self, step: int, loss: float, is_best: bool = False):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —á–µ–∫–ø–æ–∏–Ω—Ç"""
        checkpoint_config = self.config.get('checkpoint', {})
        checkpoint_dir = Path(checkpoint_config.get('dir', './checkpoints'))
        checkpoint_dir.mkdir(exist_ok=True, parents=True)
        
        # –ò–º—è —á–µ–∫–ø–æ–∏–Ω—Ç–∞
        if is_best:
            checkpoint_name = f"best_model_step_{step}_loss_{loss:.4f}"
        else:
            checkpoint_name = f"checkpoint_step_{step}_loss_{loss:.4f}"
        
        checkpoint_path = checkpoint_dir / checkpoint_name
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ
        torch.save({
            'step': step,
            'model_state_dict': self.model.state_dict(),
            'optimizer_state_dict': self.optimizer.state_dict(),
            'scheduler_state_dict': self.scheduler.state_dict(),
            'loss': loss,
            'config': self.config,
            'stats': self.stats,
            'tokenizer_config': self.tokenizer.get_vocab() if self.tokenizer else None,
        }, checkpoint_path)
        
        # –î–æ–±–∞–≤–ª—è–µ–º –≤ —Å–ø–∏—Å–æ–∫
        self.stats['checkpoint_paths'].append(str(checkpoint_path))
        
        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —á–µ–∫–ø–æ–∏–Ω—Ç–æ–≤
        save_total_limit = checkpoint_config.get('save_total_limit', 3)
        if len(self.stats['checkpoint_paths']) > save_total_limit:
            # –£–¥–∞–ª—è–µ–º —Å–∞–º—ã–π —Å—Ç–∞—Ä—ã–π
            oldest = self.stats['checkpoint_paths'].pop(0)
            try:
                Path(oldest).unlink()
            except:
                pass
        
        if is_best:
            print(f"{Fore.GREEN}üíæ –õ—É—á—à–∏–π —á–µ–∫–ø–æ–∏–Ω—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {checkpoint_path.name}{Style.RESET_ALL}")
        else:
            print(f"{Fore.BLUE}üíæ –ß–µ–∫–ø–æ–∏–Ω—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {checkpoint_path.name}{Style.RESET_ALL}")
        
        return checkpoint_path
    
    def train_epoch(self, epoch: int) -> float:
        """–û–±—É—á–∞–µ—Ç –æ–¥–Ω—É —ç–ø–æ—Ö—É"""
        print(f"\n{Fore.CYAN}{'='*70}{Style.RESET_ALL}")
        print(f"{Fore.MAGENTA}üìö –≠–ü–û–•–ê {epoch}/{self.config.get('training', {}).get('epochs', 3)}{Style.RESET_ALL}")
        print(f"{Fore.CYAN}{'='*70}{Style.RESET_ALL}")
        
        self.model.train()
        total_loss = 0
        total_samples = 0
        
        training_config = self.config.get('training', {})
        grad_accumulation = training_config.get('gradient_accumulation', 1)
        max_grad_norm = training_config.get('max_grad_norm', 1.0)
        
        # –ü—Ä–æ–≥—Ä–µ—Å—Å –±–∞—Ä
        pbar = tqdm(self.train_loader, desc=f"–≠–ø–æ—Ö–∞ {epoch}", 
                   bar_format="{l_bar}{bar:30}{r_bar}", 
                   colour="green")
        
        start_time = time.time()
        accumulation_steps = 0
        
        for batch_idx, batch in enumerate(pbar):
            # –ü–µ—Ä–µ–Ω–æ—Å–∏–º batch –Ω–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ
            input_ids = batch['input_ids'].to(self.device)
            attention_mask = batch['attention_mask'].to(self.device)
            labels = batch['labels'].to(self.device)
            
            # Forward pass
            outputs = self.model(
                input_ids=input_ids,
                attention_mask=attention_mask,
                labels=labels
            )
            
            loss = outputs.loss
            loss = loss / grad_accumulation  # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º loss –¥–ª—è accumulation
            
            # Backward pass
            loss.backward()
            
            # –ù–∞–∫–æ–ø–ª–µ–Ω–∏–µ –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤
            accumulation_steps += 1
            if accumulation_steps % grad_accumulation == 0:
                # –û–±—Ä–µ–∑–∞–µ–º –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã
                if max_grad_norm > 0:
                    torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_grad_norm)
                
                # –®–∞–≥ –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–∞
                self.optimizer.step()
                self.scheduler.step()
                self.optimizer.zero_grad()
                
                # –°—á–∏—Ç–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
                current_step = self.stats['current_epoch'] * len(self.train_loader) + batch_idx
                current_lr = self.scheduler.get_last_lr()[0]
                
                # –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥
                speed = batch_size / (time.time() - start_time) if batch_idx > 0 else 0
                start_time = time.time()
                
                self.monitor.log_step(
                    step=current_step,
                    loss=loss.item() * grad_accumulation,  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
                    lr=current_lr,
                    phase="train",
                    speed=speed,
                    epoch=epoch,
                    batch=batch_idx
                )
                
                # –û–±–Ω–æ–≤–ª—è–µ–º progress bar
                pbar.set_postfix({
                    'loss': f"{loss.item() * grad_accumulation:.4f}",
                    'lr': f"{current_lr:.2e}",
                    'speed': f"{speed:.1f}/s"
                })
            
            total_loss += loss.item() * grad_accumulation * input_ids.size(0)
            total_samples += input_ids.size(0)
        
        # –ó–∞–≤–µ—Ä—à–∞–µ–º –æ—Å—Ç–∞–≤—à–∏–µ—Å—è –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã
        if accumulation_steps % grad_accumulation != 0:
            self.optimizer.step()
            self.scheduler.step()
            self.optimizer.zero_grad()
        
        avg_loss = total_loss / total_samples if total_samples > 0 else 0
        print(f"{Fore.GREEN}‚úÖ –≠–ø–æ—Ö–∞ {epoch} –∑–∞–≤–µ—Ä—à–µ–Ω–∞{Style.RESET_ALL}")
        print(f"   –°—Ä–µ–¥–Ω–∏–π loss: {avg_loss:.4f}")
        
        return avg_loss
    
    def validate(self) -> float:
        """–í–∞–ª–∏–¥–∞—Ü–∏—è –º–æ–¥–µ–ª–∏"""
        print(f"\n{Fore.CYAN}üß™ –í–ê–õ–ò–î–ê–¶–ò–Ø{Style.RESET_ALL}")
        print(f"{Fore.CYAN}{'-'*40}{Style.RESET_ALL}")
        
        self.model.eval()
        total_loss = 0
        total_samples = 0
        
        with torch.no_grad():
            val_bar = tqdm(self.val_loader, desc="–í–∞–ª–∏–¥–∞—Ü–∏—è", 
                          bar_format="{l_bar}{bar:30}{r_bar}", 
                          colour="yellow")
            
            for batch_idx, batch in enumerate(val_bar):
                input_ids = batch['input_ids'].to(self.device)
                attention_mask = batch['attention_mask'].to(self.device)
                labels = batch['labels'].to(self.device)
                
                outputs = self.model(
                    input_ids=input_ids,
                    attention_mask=attention_mask,
                    labels=labels
                )
                
                loss = outputs.loss
                total_loss += loss.item() * input_ids.size(0)
                total_samples += input_ids.size(0)
                
                # –û–±–Ω–æ–≤–ª—è–µ–º progress bar
                current_loss = total_loss / total_samples if total_samples > 0 else 0
                val_bar.set_postfix({'loss': f"{current_loss:.4f}"})
        
        avg_loss = total_loss / total_samples if total_samples > 0 else 0
        print(f"{Fore.GREEN}‚úÖ –í–∞–ª–∏–¥–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞{Style.RESET_ALL}")
        print(f"   Val loss: {avg_loss:.4f}")
        
        return avg_loss
    
    def train(self):
        """–û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª –æ–±—É—á–µ–Ω–∏—è"""
        print(f"\n{Fore.CYAN}{'='*70}{Style.RESET_ALL}")
        print(f"{Fore.MAGENTA}üöÄ –ù–ê–ß–ê–õ–û –û–ë–£–ß–ï–ù–ò–Ø{Style.RESET_ALL}")
        print(f"{Fore.CYAN}{'='*70}{Style.RESET_ALL}")
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        dialogues = self.load_data()
        
        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
        self.prepare_tokenizer()
        self.prepare_model()
        self.create_datasets(dialogues)
        self.create_dataloaders()
        self.prepare_optimizer()
        
        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–±—É—á–µ–Ω–∏—è
        training_config = self.config.get('training', {})
        epochs = training_config.get('epochs', 3)
        checkpoint_config = self.config.get('checkpoint', {})
        
        save_steps = checkpoint_config.get('save_steps', 100)
        load_best = checkpoint_config.get('load_best_model_at_end', True)
        patience = checkpoint_config.get('early_stopping', {}).get('patience', 3)
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        best_val_loss = float('inf')
        patience_counter = 0
        
        # –ì–ª–∞–≤–Ω—ã–π —Ü–∏–∫–ª –æ–±—É—á–µ–Ω–∏—è
        for epoch in range(1, epochs + 1):
            self.stats['current_epoch'] = epoch
            
            # –¢—Ä–µ–Ω–∏—Ä–æ–≤–∫–∞
            train_loss = self.train_epoch(epoch)
            
            # –í–∞–ª–∏–¥–∞—Ü–∏—è
            val_loss = self.validate()
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ª—É—á—à—É—é –º–æ–¥–µ–ª—å
            is_best = val_loss < best_val_loss
            if is_best:
                best_val_loss = val_loss
                self.stats['best_loss'] = best_val_loss
                patience_counter = 0
                print(f"{Fore.GREEN}üéØ –ù–æ–≤—ã–π –ª—É—á—à–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç: {best_val_loss:.4f}{Style.RESET_ALL}")
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ª—É—á—à—É—é –º–æ–¥–µ–ª—å
                self.save_checkpoint(
                    step=epoch * len(self.train_loader),
                    loss=best_val_loss,
                    is_best=True
                )
            else:
                patience_counter += 1
                print(f"{Fore.YELLOW}‚ö†Ô∏è  –ü–∞–¥–µ–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–∞, patience: {patience_counter}/{patience}{Style.RESET_ALL}")
            
            # –†–∞–Ω–Ω—è—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∞
            if patience_counter >= patience:
                print(f"{Fore.RED}üõë –†–∞–Ω–Ω—è—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∞ –Ω–∞ —ç–ø–æ—Ö–µ {epoch}{Style.RESET_ALL}")
                break
            
            # –†–µ–≥—É–ª—è—Ä–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
            if epoch % max(1, save_steps // len(self.train_loader)) == 0:
                self.save_checkpoint(
                    step=epoch * len(self.train_loader),
                    loss=val_loss,
                    is_best=False
                )
        
        # –§–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç
        self.monitor.final_report()
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—É—é –º–æ–¥–µ–ª—å –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        if load_best:
            print(f"\n{Fore.CYAN}üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏...{Style.RESET_ALL}")
            self.save_checkpoint(
                step=epochs * len(self.train_loader),
                loss=best_val_loss,
                is_best=True
            )
        
        print(f"\n{Fore.GREEN}‚ú® –û–ë–£–ß–ï–ù–ò–ï –£–°–ü–ï–®–ù–û –ó–ê–í–ï–†–®–ï–ù–û ‚ú®{Style.RESET_ALL}")
        
        return best_val_loss

# ============================================================================
# –ì–õ–ê–í–ù–ê–Ø –§–£–ù–ö–¶–ò–Ø
# ============================================================================

def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∑–∞–ø—É—Å–∫–∞ –æ–±—É—á–µ–Ω–∏—è"""
    parser = argparse.ArgumentParser(description="–¢—Ä–µ–Ω–µ—Ä –ø—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–≥–æ –ò–ò")
    parser.add_argument("--config", type=str, default="./configs/base.json", 
                       help="–ü—É—Ç—å –∫ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–æ–Ω–Ω–æ–º—É —Ñ–∞–π–ª—É")
    parser.add_argument("--preset", type=str, default=None,
                       help="–ü—Ä–µ—Å–µ—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ (fast, quality, debug)")
    parser.add_argument("--resume", type=str, default=None,
                       help="–ü—É—Ç—å –∫ —á–µ–∫–ø–æ–∏–Ω—Ç—É –¥–ª—è –≤–æ–∑–æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –æ–±—É—á–µ–Ω–∏—è")
    args = parser.parse_args()
    
    try:
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
        print(f"{Fore.CYAN}{'='*70}{Style.RESET_ALL}")
        print(f"{Fore.MAGENTA}{Style.BRIGHT}üß† RUZANNA - PSYCHOLOGICAL AI TRAINER{Style.RESET_ALL}")
        print(f"{Fore.CYAN}{'='*70}{Style.RESET_ALL}")
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        print(f"{Fore.BLUE}üìÑ –ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏...{Style.RESET_ALL}")
        config_manager = ConfigManager("./configs")
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å —É—á–µ—Ç–æ–º –ø—Ä–µ—Å–µ—Ç–∞
        config = config_manager.load_full_config(preset=args.preset)
        
        # –ü–æ–ª—É—á–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
        params = config_manager.get_training_params()
        
        print(f"{Fore.GREEN}‚úÖ –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∑–∞–≥—Ä—É–∂–µ–Ω–∞{Style.RESET_ALL}")
        print(f"   –ú–æ–¥–µ–ª—å: {params.get('model_name')}")
        print(f"   –î–∞–Ω–Ω—ã–µ: {Path(params.get('data_path', '')).name}")
        print(f"   Batch size: {params.get('batch_size')}")
        print(f"   –≠–ø–æ—Ö–∏: {params.get('epochs')}")
        print(f"   Learning rate: {params.get('learning_rate'):.2e}")
        
        # –°–æ–∑–¥–∞–µ–º —Ç—Ä–µ–Ω–µ—Ä
        trainer = PsychAITrainer(config)
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ
        best_loss = trainer.train()
        
        print(f"\n{Fore.GREEN}{'='*70}{Style.RESET_ALL}")
        print(f"{Fore.MAGENTA}üèÜ –õ–£–ß–®–ò–ô –†–ï–ó–£–õ–¨–¢–ê–¢: {best_loss:.4f}{Style.RESET_ALL}")
        print(f"{Fore.GREEN}{'='*70}{Style.RESET_ALL}")
        
    except KeyboardInterrupt:
        print(f"\n{Fore.YELLOW}‚ö†Ô∏è  –û–±—É—á–µ–Ω–∏–µ –ø—Ä–µ—Ä–≤–∞–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º{Style.RESET_ALL}")
    except Exception as e:
        print(f"\n{Fore.RED}‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}{Style.RESET_ALL}")
        import traceback
        traceback.print_exc()
        sys.exit(1)

# ============================================================================
# –ó–ê–ü–£–°–ö
# ============================================================================

if __name__ == "__main__":
    main()
